{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# ðŸ“„ Customer Churn Dataset Generator\n",
        "\n",
        "Generates synthetic customer data for a hosting/domain service business with churn labels driven by configurable behavioral patterns.\n",
        "\n",
        "## Features\n",
        "- Pattern-based churn logic (not random)\n",
        "- Realistic data distributions\n",
        "- Configurable parameters\n",
        "- Fast generation (<2s for 100 records)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies if needed\n",
        "# !pip install pandas numpy faker\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from faker import Faker\n",
        "import uuid\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ… Dependencies loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## ðŸ”§ Configuration\n",
        "\n",
        "Modify these parameters to customize your dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "N_CUSTOMERS = 100  # Number of customer records\n",
        "RANDOM_SEED = 42   # Set to None for random results, or integer for reproducible results\n",
        "OUTPUT_FILE = 'churn_dataset_realistic.csv'\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "if RANDOM_SEED is not None:\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    Faker.seed(RANDOM_SEED)\n",
        "\n",
        "fake = Faker()\n",
        "print(f\"ðŸ“Š Configured to generate {N_CUSTOMERS} records with seed={RANDOM_SEED}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## ðŸŽ² Data Generation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_basic_info(n_customers):\n",
        "    \"\"\"Generate basic customer information.\"\"\"\n",
        "    return {\n",
        "        'customer_id': [str(uuid.uuid4()) for _ in range(n_customers)],\n",
        "        'customer_name': [fake.name() for _ in range(n_customers)],\n",
        "        'customer_email': [fake.email() for _ in range(n_customers)]\n",
        "    }\n",
        "\n",
        "def generate_support_metrics(n_customers):\n",
        "    \"\"\"Generate support-related metrics.\"\"\"\n",
        "    support_tickets = np.random.poisson(lam=2, size=n_customers)\n",
        "    support_tickets = np.clip(support_tickets, 0, 10)\n",
        "    \n",
        "    # Resolution time correlates with ticket volume\n",
        "    base_resolution = np.random.exponential(scale=24, size=n_customers)\n",
        "    ticket_multiplier = 1 + (support_tickets / 10)\n",
        "    avg_resolution_time = base_resolution * ticket_multiplier\n",
        "    avg_resolution_time = np.clip(avg_resolution_time, 1, 200)\n",
        "    \n",
        "    # Critical tickets are subset of total tickets\n",
        "    critical_tickets_sla_breach = np.random.binomial(\n",
        "        n=np.minimum(support_tickets, 4), \n",
        "        p=0.3, \n",
        "        size=n_customers\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        'support_tickets': support_tickets,\n",
        "        'avg_resolution_time': np.round(avg_resolution_time, 2),\n",
        "        'critical_tickets_sla_breach': critical_tickets_sla_breach\n",
        "    }\n",
        "\n",
        "def generate_product_metrics(n_customers):\n",
        "    \"\"\"Generate product and subscription metrics.\"\"\"\n",
        "    # Tenure follows realistic distribution\n",
        "    tenure_months = np.random.gamma(shape=2, scale=8, size=n_customers)\n",
        "    tenure_months = np.clip(tenure_months, 1, 48).astype(int)\n",
        "    \n",
        "    # Product renewals depend on tenure\n",
        "    renewal_probability = np.minimum(tenure_months / 24, 0.8)\n",
        "    product_renewals = np.random.binomial(n=5, p=renewal_probability)\n",
        "    \n",
        "    # Monthly spend follows log-normal distribution\n",
        "    monthly_spend = np.random.lognormal(mean=3.5, sigma=0.8, size=n_customers)\n",
        "    monthly_spend = np.clip(monthly_spend, 5, 150)\n",
        "    \n",
        "    # Total products correlates with spend\n",
        "    spend_tier = np.digitize(monthly_spend, bins=[0, 25, 50, 100, 150])\n",
        "    total_products = np.random.poisson(lam=spend_tier, size=n_customers)\n",
        "    total_products = np.clip(total_products, 1, 10)\n",
        "    \n",
        "    # Products transferred out (churn indicator)\n",
        "    transfer_probability = np.random.beta(a=1, b=9, size=n_customers)\n",
        "    products_transferred_out = np.random.binomial(\n",
        "        n=np.minimum(total_products, 3), \n",
        "        p=transfer_probability\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        'product_renewals': product_renewals,\n",
        "        'tenure_months': tenure_months,\n",
        "        'monthly_spend': np.round(monthly_spend, 2),\n",
        "        'total_products': total_products,\n",
        "        'products_transferred_out': products_transferred_out\n",
        "    }\n",
        "\n",
        "def generate_performance_metrics(n_customers):\n",
        "    \"\"\"Generate system performance metrics.\"\"\"\n",
        "    # Load time follows log-normal (most fast, some very slow)\n",
        "    avg_load_time = np.random.lognormal(mean=1.2, sigma=0.8, size=n_customers)\n",
        "    avg_load_time = np.clip(avg_load_time, 0.5, 15)\n",
        "    \n",
        "    # Downtime follows exponential distribution\n",
        "    downtime_minutes = np.random.exponential(scale=30, size=n_customers)\n",
        "    downtime_minutes = np.clip(downtime_minutes, 0, 300).astype(int)\n",
        "    \n",
        "    # Product usage - beta distribution creates realistic usage patterns\n",
        "    product_usage_percent = np.random.beta(a=2, b=2, size=n_customers) * 100\n",
        "    product_usage_percent = np.clip(product_usage_percent, 0, 100)\n",
        "    \n",
        "    return {\n",
        "        'avg_load_time': np.round(avg_load_time, 2),\n",
        "        'downtime_minutes': downtime_minutes,\n",
        "        'product_usage_percent': np.round(product_usage_percent, 1)\n",
        "    }\n",
        "\n",
        "def generate_last_login(tenure_months):\n",
        "    \"\"\"Generate last login dates based on tenure.\"\"\"\n",
        "    today = datetime.now()\n",
        "    last_logins = []\n",
        "    \n",
        "    for tenure in tenure_months:\n",
        "        # Recent customers login more frequently\n",
        "        if tenure < 6:\n",
        "            days_ago = np.random.exponential(scale=10)\n",
        "        elif tenure < 12:\n",
        "            days_ago = np.random.exponential(scale=20)\n",
        "        else:\n",
        "            days_ago = np.random.exponential(scale=35)\n",
        "        \n",
        "        days_ago = min(days_ago, tenure * 30)  # Can't login before becoming customer\n",
        "        last_login = today - timedelta(days=int(days_ago))\n",
        "        last_logins.append(last_login.strftime('%Y-%m-%d'))\n",
        "    \n",
        "    return last_logins\n",
        "\n",
        "print(\"âœ… Data generation functions defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## ðŸŽ¯ Churn Logic\n",
        "\n",
        "This implements the rule-based scoring system from the PRD:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_churn_score(df):\n",
        "    \"\"\"Calculate churn score based on rule-based logic from PRD.\"\"\"\n",
        "    scores = np.zeros(len(df))\n",
        "    \n",
        "    # Calculate days since last login\n",
        "    today = datetime.now()\n",
        "    last_login_dates = pd.to_datetime(df['last_login'])\n",
        "    days_since_login = (today - last_login_dates).dt.days\n",
        "    \n",
        "    # Apply scoring rules from PRD\n",
        "    conditions = [\n",
        "        ('Support tickets > 4', df['support_tickets'] > 4),\n",
        "        ('Avg resolution time > 48h', df['avg_resolution_time'] > 48),\n",
        "        ('Critical SLA breaches > 1', df['critical_tickets_sla_breach'] > 1),\n",
        "        ('Product renewals < 2', df['product_renewals'] < 2),\n",
        "        ('Tenure < 6 months', df['tenure_months'] < 6),\n",
        "        ('Monthly spend < $20', df['monthly_spend'] < 20),\n",
        "        ('Last login > 45 days ago', days_since_login > 45),\n",
        "        ('Products transferred out > 1', df['products_transferred_out'] > 1),\n",
        "        ('Avg load time > 5s', df['avg_load_time'] > 5),\n",
        "        ('Downtime > 120 min', df['downtime_minutes'] > 120),\n",
        "        ('Product usage < 30%', df['product_usage_percent'] < 30)\n",
        "    ]\n",
        "    \n",
        "    # Sum up the scores and show breakdown\n",
        "    print(\"ðŸŽ¯ Churn Scoring Rules Applied:\")\n",
        "    for rule_name, condition in conditions:\n",
        "        rule_score = condition.sum()\n",
        "        scores += condition.astype(int)\n",
        "        print(f\"   {rule_name}: {rule_score} customers affected\")\n",
        "    \n",
        "    return scores\n",
        "\n",
        "def assign_churn_status(scores):\n",
        "    \"\"\"Assign churn status based on scores with 10% noise.\"\"\"\n",
        "    # Base assignment: score >= 5 means inactive\n",
        "    base_status = ['inactive' if score >= 5 else 'active' for score in scores]\n",
        "    \n",
        "    # Add 10% noise (random flips)\n",
        "    noise_indices = np.random.choice(\n",
        "        len(base_status), \n",
        "        size=int(0.1 * len(base_status)), \n",
        "        replace=False\n",
        "    )\n",
        "    \n",
        "    final_status = base_status.copy()\n",
        "    for idx in noise_indices:\n",
        "        final_status[idx] = 'inactive' if final_status[idx] == 'active' else 'active'\n",
        "    \n",
        "    print(f\"\\nðŸ“Š Churn Assignment Summary:\")\n",
        "    print(f\"   Base rule assignment: {base_status.count('inactive')} inactive / {len(base_status)} total\")\n",
        "    print(f\"   After 10% noise: {final_status.count('inactive')} inactive / {len(final_status)} total\")\n",
        "    \n",
        "    return final_status\n",
        "\n",
        "print(\"âœ… Churn logic functions defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## ðŸš€ Generate Dataset\n",
        "\n",
        "Run this cell to generate your synthetic churn dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "print(f\"ðŸŽ² Generating {N_CUSTOMERS} customer records...\\n\")\n",
        "\n",
        "# Generate all data components\n",
        "basic_info = generate_basic_info(N_CUSTOMERS)\n",
        "support_metrics = generate_support_metrics(N_CUSTOMERS)\n",
        "product_metrics = generate_product_metrics(N_CUSTOMERS)\n",
        "performance_metrics = generate_performance_metrics(N_CUSTOMERS)\n",
        "\n",
        "# Combine into DataFrame\n",
        "data = {**basic_info, **support_metrics, **product_metrics, **performance_metrics}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Generate last login based on tenure\n",
        "df['last_login'] = generate_last_login(df['tenure_months'])\n",
        "\n",
        "# Calculate churn scores and assign status\n",
        "churn_scores = calculate_churn_score(df)\n",
        "df['customer_status'] = assign_churn_status(churn_scores)\n",
        "\n",
        "# Reorder columns to match PRD schema\n",
        "column_order = [\n",
        "    'customer_id', 'customer_name', 'customer_email',\n",
        "    'support_tickets', 'avg_resolution_time', 'critical_tickets_sla_breach',\n",
        "    'product_renewals', 'tenure_months', 'monthly_spend',\n",
        "    'last_login', 'total_products', 'products_transferred_out',\n",
        "    'avg_load_time', 'downtime_minutes', 'product_usage_percent',\n",
        "    'customer_status'\n",
        "]\n",
        "\n",
        "df_final = df[column_order]\n",
        "\n",
        "# Save to CSV\n",
        "df_final.to_csv(OUTPUT_FILE, index=False)\n",
        "\n",
        "print(f\"\\nâœ… Dataset generated and saved to: {OUTPUT_FILE}\")\n",
        "print(f\"ðŸ“Š Shape: {df_final.shape}\")\n",
        "print(f\"ðŸ“ˆ Churn rate: {(df_final['customer_status'] == 'inactive').mean():.1%}\")\n",
        "\n",
        "# Preview first 5 rows\n",
        "print(f\"\\nðŸ“‹ Preview (first 5 rows):\")\n",
        "display(df_final.head())\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
